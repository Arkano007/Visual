{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador Léxico\n",
    "Su función es analizar una secuencia de caracteres para convertirla en una secuencia de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# Definición de tipos de token\n",
    "\n",
    "class TipoToken(Enum):\n",
    "    O = 1\n",
    "    Y = 2\n",
    "    S = 3\n",
    "    N = 4\n",
    "    E = 5\n",
    "    P = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "# Clase Nodo para el árbol de expresiones\n",
    "\n",
    "class NodoExpresion:\n",
    "    def __init__(self, valor: str, tipo: TipoToken):\n",
    "        self.valor = valor\n",
    "        self.tipo = tipo\n",
    "        self.izquierda = None\n",
    "        self.derecha = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para el analizador léxico\n",
    "\n",
    "def analizador_lexico(entrada: str) -> List[Dict]:\n",
    "\n",
    "    # Separar cadena en palabras\n",
    "\n",
    "    tokens = entrada.lower().split()\n",
    "    \n",
    "    # Etiquetar cada palabra con su respectivo tipo de token\n",
    "    \n",
    "    lexemas = []\n",
    "    for token in tokens:\n",
    "        if token == 'o':\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.O})\n",
    "        elif token == 'y':\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.Y})\n",
    "        elif token == 'si':\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.S})\n",
    "        elif token == 'entonces':\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.E})\n",
    "        elif token == 'no':\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.N})\n",
    "        else:\n",
    "            lexemas.append({\"valor\": token, \"tipo\": TipoToken.P})\n",
    "            \n",
    "    return lexemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador sintáctico\n",
    "Analiza la estructura sintáctica del código fuente para determinar si está correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de estados del analizador sintáctico\n",
    "\n",
    "class EstadosAnalizador(Enum):\n",
    "    INICIO = 1\n",
    "    CONDICIONAL = 2\n",
    "    PRECEDENTE = 3\n",
    "    ERROR = 4\n",
    "    NEGACION_i = 5\n",
    "    NEGACION_f = 6\n",
    "    NEGACION_s = 7\n",
    "    CONECTOR = 8\n",
    "    ATOMO = 9\n",
    "    DISYUNCION = 10\n",
    "    ATOMOF = 11\n",
    "    CONJUNCION = 12\n",
    "    FIN = 13  # Estado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para el analizador sintáctico\n",
    "\n",
    "def analizador_sintactico(lexemas: List[Dict], reglas_simbolos: List[List[Dict]]) -> EstadosAnalizador:\n",
    "    EstadoActual = EstadosAnalizador.INICIO\n",
    "    lista_atomos = []\n",
    "    atomo_temporal = []\n",
    "    lexema_anterior = \"\"\n",
    "\n",
    "    for l in lexemas:\n",
    "        lexema = l[\"valor\"]\n",
    "        \n",
    "        # Estado INICIO\n",
    "\n",
    "        if EstadoActual == EstadosAnalizador.INICIO:\n",
    "            if lexema == \"si\":\n",
    "                EstadoActual = EstadosAnalizador.CONDICIONAL\n",
    "            elif lexema == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION_i\n",
    "            elif lexema in [\"y\", \"o\", \"entonces\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "        \n",
    "        # Estado NEGACION_i\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.NEGACION_i:\n",
    "            if lexema in [\"si\", \"y\", \"o\", \"entonces\", \"no\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "        \n",
    "        # Estado ATOMO\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.ATOMO:\n",
    "            atomo_temporal.append(l)\n",
    "            if lexema in [\"no\", \"entonces\", \"si\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            elif lexema in [\"y\", \"o\"]:\n",
    "                EstadoActual = EstadosAnalizador.CONECTOR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "        \n",
    "        # Estado CONDICIONAL\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.CONDICIONAL:\n",
    "            if lexema == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION_s\n",
    "            elif lexema in [\"entonces\", \"y\", \"o\", \"si\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.PRECEDENTE\n",
    "        \n",
    "        # Estado NEGACION_s\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.NEGACION_s:\n",
    "            if lexema in [\"y\", \"o\", \"entonces\", \"si\", \"no\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.PRECEDENTE\n",
    "        \n",
    "        # Estado PRECEDENTE\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.PRECEDENTE:\n",
    "            if lexema == \"entonces\":\n",
    "                EstadoActual = EstadosAnalizador.CONECTOR\n",
    "            elif lexema in [\"no\", \"y\", \"o\", \"si\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.PRECEDENTE\n",
    "        \n",
    "        # Estado CONECTOR\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.CONECTOR:\n",
    "            if lexema in [\"y\", \"o\", \"si\", \"entonces\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            elif lexema == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION_f\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMOF\n",
    "        \n",
    "        # Estado NEGACION_f\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.NEGACION_f:\n",
    "            if lexema in [\"y\", \"o\", \"si\", \"entonces\", \"no\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMOF\n",
    "        \n",
    "        # Estado CONJUNCION\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.CONJUNCION:\n",
    "            if lexema in [\"entonces\", \"si\", \"o\", \"y\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            elif lexema == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION_f\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMOF\n",
    "        \n",
    "        # Estado DISYUNCION\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.DISYUNCION:\n",
    "            if lexema in [\"y\", \"o\", \"si\", \"entonces\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            elif lexema == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION_f\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMOF\n",
    "        \n",
    "        # Estado ATOMOF\n",
    "\n",
    "        elif EstadoActual == EstadosAnalizador.ATOMOF:\n",
    "            if lexema in [\"y\", \"o\", \"si\", \"entonces\", \"no\"]:\n",
    "                EstadoActual = EstadosAnalizador.ERROR\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ATOMOF\n",
    "        \n",
    "        elif EstadoActual == EstadosAnalizador.ERROR:\n",
    "            print(\"Tu proposición está mal escrita\")\n",
    "            break\n",
    "    \n",
    "    if EstadoActual == EstadosAnalizador.ATOMOF:\n",
    "        return EstadosAnalizador.FIN\n",
    "    else:\n",
    "        return EstadosAnalizador.ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador semántico\n",
    "Comprueba reglas adicionales que no son posibles de verificar en la etapa léxica o sintáctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para el analizador semántico\n",
    "\n",
    "def analizador_semantico(lexemas: list) -> bool:\n",
    "\n",
    "    tiene_si = False\n",
    "    tiene_entonces = False\n",
    "    tiene_conector = False\n",
    "    tiene_negacion = False\n",
    "\n",
    "    for lexema in lexemas:\n",
    "        tipo = lexema[\"tipo\"]\n",
    "        \n",
    "        if tipo == TipoToken.S:\n",
    "            tiene_si = True\n",
    "        elif tipo == TipoToken.E:\n",
    "            tiene_entonces = True\n",
    "        elif tipo in [TipoToken.O, TipoToken.Y]:\n",
    "            tiene_conector = True\n",
    "        elif tipo == TipoToken.N:\n",
    "            tiene_negacion = True\n",
    "    return tiene_si and tiene_entonces and (not tiene_conector or any(lexema[\"tipo\"] == TipoToken.P for lexema in lexemas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lector de reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer las reglas desde un archivo\n",
    "\n",
    "def leer_reglas(nombre_archivo: str) -> list:\n",
    "    try:\n",
    "        with open(nombre_archivo, 'r') as file:\n",
    "            reglas = file.readlines()\n",
    "        return [regla.strip() for regla in reglas if regla.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo '{nombre_archivo}' no se encuentra.\")\n",
    "        raise\n",
    "    except IOError as e:\n",
    "        print(f\"Error al leer el archivo '{nombre_archivo}': {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer las reglas desde el archivo\n",
    "\n",
    "nombre_archivo = \"reglas.txt\"\n",
    "try:\n",
    "    reglas = leer_reglas(nombre_archivo)\n",
    "    print(\"Reglas leídas del archivo:\")\n",
    "    for regla in reglas:\n",
    "        print(regla)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir reglas a símbolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Función para convertir las reglas en símbolos para el analizador sintáctico\n",
    "\n",
    "def convertir_a_simbolos(reglas: List[str], analizador_lexico) -> List[List[dict]]:\n",
    "   \n",
    "    reglas_simbolos = []\n",
    "    for regla in reglas:\n",
    "        lexemas = analizador_lexico(regla)\n",
    "        reglas_simbolos.append(lexemas)\n",
    "    return reglas_simbolos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir la tabla de reglas para mostrar\n",
    "\n",
    "nombre_archivo = \"reglas.txt\"\n",
    "try:\n",
    "    reglas = leer_reglas(nombre_archivo)\n",
    "    reglas_simbolos = convertir_a_simbolos(reglas, analizador_lexico)\n",
    "    print(\"Reglas convertidas a símbolos:\")\n",
    "    for regla_simbolos in reglas_simbolos:\n",
    "        print(regla_simbolos)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir la tabla de reglas para mostrar\n",
    "\n",
    "def construir_tabla_reglas(reglas_simbolos: list) -> dict:\n",
    "    tabla_reglas = {}\n",
    "\n",
    "    for i, regla_simbolos in enumerate(reglas_simbolos, start=1):\n",
    "        tabla_reglas[f\"Regla {i}\"] = regla_simbolos\n",
    "\n",
    "    return tabla_reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la tabla de reglas para mostrar\n",
    "\n",
    "nombre_archivo = \"reglas.txt\"\n",
    "try:\n",
    "    reglas = leer_reglas(nombre_archivo)\n",
    "    reglas_simbolos = convertir_a_simbolos(reglas, analizador_lexico)\n",
    "    tabla_reglas = construir_tabla_reglas(reglas_simbolos)\n",
    "    print(\"Tabla de reglas:\")\n",
    "    for key, value in tabla_reglas.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "# Implementación del árbol binario para expresiones\n",
    "\n",
    "class Nodo:\n",
    "    def __init__(self, valor):\n",
    "        self.valor = valor\n",
    "        self.izquierda = None\n",
    "        self.derecha = None\n",
    "\n",
    "class ArbolBinario:\n",
    "    def __init__(self):\n",
    "        self.raiz = None\n",
    "\n",
    "    def insertar(self, valor):\n",
    "        nuevo_nodo = Nodo(valor)\n",
    "        if self.raiz is None:\n",
    "            self.raiz = nuevo_nodo\n",
    "        else:\n",
    "            cola = [self.raiz]\n",
    "            while cola:\n",
    "                nodo_actual = cola.pop(0)\n",
    "                if nodo_actual.izquierda is None:\n",
    "                    nodo_actual.izquierda = nuevo_nodo\n",
    "                    break\n",
    "                else:\n",
    "                    cola.append(nodo_actual.izquierda)\n",
    "                \n",
    "                if nodo_actual.derecha is None:\n",
    "                    nodo_actual.derecha = nuevo_nodo\n",
    "                    break\n",
    "                else:\n",
    "                    cola.append(nodo_actual.derecha)\n",
    "\n",
    "    def bfs(self):\n",
    "        if self.raiz is None:\n",
    "            return []\n",
    "\n",
    "        resultado = []\n",
    "        cola = [self.raiz]\n",
    "        while cola:\n",
    "            nodo_actual = cola.pop(0)\n",
    "            resultado.append(nodo_actual)\n",
    "            if nodo_actual.izquierda:\n",
    "                cola.append(nodo_actual.izquierda)\n",
    "            if nodo_actual.derecha:\n",
    "                cola.append(nodo_actual.derecha)\n",
    "\n",
    "        return resultado\n",
    "\n",
    "    def dfs(self):\n",
    "        if self.raiz is None:\n",
    "            return []\n",
    "\n",
    "        def dfs_recursivo(nodo, resultado):\n",
    "            if nodo:\n",
    "                resultado.append(nodo)\n",
    "                dfs_recursivo(nodo.izquierda, resultado)\n",
    "                dfs_recursivo(nodo.derecha, resultado)\n",
    "\n",
    "        resultado = []\n",
    "        dfs_recursivo(self.raiz, resultado)\n",
    "        return resultado\n",
    "\n",
    "def construir_arbol():\n",
    "    arbol = ArbolBinario()\n",
    "\n",
    "    # Ejemplo de árbol de expresiones\n",
    "    arbol.insertar('->')\n",
    "    arbol.raiz.izquierda = Nodo('es de día')\n",
    "    arbol.raiz.derecha = Nodo('v')\n",
    "    arbol.raiz.derecha.izquierda = Nodo('hace calor')\n",
    "    arbol.raiz.derecha.derecha = Nodo('hace frío')\n",
    "\n",
    "    return arbol\n",
    "\n",
    "def visualize_tree(arbol):\n",
    "    dot = graphviz.Digraph(format='png')\n",
    "\n",
    "    def traverse(nodo, parent=None):\n",
    "        dot.node(str(id(nodo)), nodo.valor)\n",
    "        if parent is not None:\n",
    "            dot.edge(str(id(parent)), str(id(nodo)))\n",
    "        if nodo.izquierda:\n",
    "            traverse(nodo.izquierda, nodo)\n",
    "        if nodo.derecha:\n",
    "            traverse(nodo.derecha, nodo)\n",
    "\n",
    "    traverse(arbol.raiz)\n",
    "    display(dot)\n",
    "\n",
    "# Crear y visualizar el árbol\n",
    "arbol = construir_arbol()\n",
    "visualize_tree(arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir árbol de expresiones\n",
    "def construir_arbol_expresion(lexemas: List[Dict]) -> ArbolBinario:\n",
    "    if not lexemas:\n",
    "        return ArbolBinario()\n",
    "    \n",
    "    arbol = ArbolBinario()\n",
    "    raiz = NodoExpresion(lexemas[0][\"valor\"], lexemas[0][\"tipo\"])\n",
    "    arbol.insertar(raiz)\n",
    "    pila = [raiz]\n",
    "    idx = 1\n",
    "\n",
    "    while pila and idx < len(lexemas):\n",
    "        nodo_actual = pila.pop()\n",
    "\n",
    "        if nodo_actual.tipo in [TipoToken.Y, TipoToken.O]:\n",
    "            nodo_actual.izquierda = NodoExpresion(lexemas[idx][\"valor\"], lexemas[idx][\"tipo\"])\n",
    "            arbol.insertar(nodo_actual.izquierda)\n",
    "            pila.append(nodo_actual.izquierda)\n",
    "            idx += 1\n",
    "\n",
    "            if idx < len(lexemas) and lexemas[idx][\"tipo\"] in [TipoToken.P, TipoToken.S, TipoToken.N]:\n",
    "                nodo_actual.derecha = NodoExpresion(lexemas[idx][\"valor\"], lexemas[idx][\"tipo\"])\n",
    "                arbol.insertar(nodo_actual.derecha)\n",
    "                pila.append(nodo_actual.derecha)\n",
    "                idx += 1\n",
    "        elif nodo_actual.tipo in [TipoToken.P, TipoToken.S, TipoToken.N]:\n",
    "            nodo_actual.derecha = NodoExpresion(lexemas[idx][\"valor\"], lexemas[idx][\"tipo\"])\n",
    "            arbol.insertar(nodo_actual.derecha)\n",
    "            pila.append(nodo_actual.derecha)\n",
    "            idx += 1\n",
    "\n",
    "    return arbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución de analizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lógica principal\n",
    "\n",
    "def main():\n",
    "    # Lectura de reglas\n",
    "    nombre_archivo = \"reglas.txt\"\n",
    "    reglas = leer_reglas(nombre_archivo)\n",
    "\n",
    "    # Convertir reglas en símbolos\n",
    "    reglas_simbolos = convertir_a_simbolos(reglas, analizador_lexico)\n",
    "\n",
    "    # Construir tabla de reglas para mostrar\n",
    "    tabla_reglas = construir_tabla_reglas(reglas_simbolos)\n",
    "\n",
    "    # Frases para analizar\n",
    "    frases = [\n",
    "        \"si P entonces Q\",\n",
    "        \"no si P y no Q entonces R\",\n",
    "        \"si P y Q o R entonces no S\",\n",
    "        \"si no P entonces no Q\",\n",
    "        \"si P entonces no P\"\n",
    "    ]\n",
    "\n",
    "    # Crear árbol binario y construir árboles de expresión\n",
    "    arbol = ArbolBinario()\n",
    "    arboles_expresion = []\n",
    "\n",
    "    for frase in frases:\n",
    "        lexemas = analizador_lexico(frase)\n",
    "        resultado_sintactico = analizador_sintactico(lexemas, reglas_simbolos)\n",
    "        es_valido = analizador_semantico(lexemas)\n",
    "\n",
    "        print(frase)\n",
    "        if resultado_sintactico == EstadosAnalizador.FIN and es_valido:\n",
    "            print(\"La frase es válida.\")\n",
    "            arbol_expresion = construir_arbol_expresion(lexemas)\n",
    "            arboles_expresion.append(arbol_expresion)\n",
    "        else:\n",
    "            print(\"La frase no es válida.\")\n",
    "\n",
    "        print(\"Resultado sintáctico:\", resultado_sintactico)\n",
    "        print(\"Resultado semántico:\", es_valido)\n",
    "        print()\n",
    "\n",
    "    # Mostrar tabla de reglas\n",
    "    print(\"Tabla de Reglas:\")\n",
    "    for nombre_regla, regla_simbolos in tabla_reglas.items():\n",
    "        print(nombre_regla)\n",
    "        for simbolo in regla_simbolos:\n",
    "            print(simbolo)\n",
    "        print()\n",
    "\n",
    "    # Mostrar árboles de expresión en BFS y DFS\n",
    "    for i, arbol_expresion in enumerate(arboles_expresion, start=1):\n",
    "        print(f\"Árbol de Expresión {i} (BFS):\")\n",
    "        print(arbol_expresion.bfs())\n",
    "        print()\n",
    "        print(f\"Árbol de Expresión {i} (DFS):\")\n",
    "        print(arbol_expresion.dfs())\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
